---
title: "Running Vital locally"
slug: "run-locally"
hidden: false
createdAt: "2022-05-04T15:30:26.145Z"
updatedAt: "2022-05-04T15:29:12.162Z"
sidebar_position: 1
---

import { Image } from "@chakra-ui/react";
import { CodeBlock } from "@theme/codeblock";

If you want to contribute to Vital by adding a new integration, or test the [existing ones](/providers/Introduction), you can run our stack locally through docker compose. The only requirements are:

* Docker
* A local copy of [vital mono](https://github.com/adeptlabs/vital-mono)

The following step-by-step guide will show you how to set up the environment, launch the stack and start fetching data.

### Setting secrets

The first step is to set the secrets.

Secrets used by docker composed are set in the [.env.dev](https://github.com/adeptlabs/vital-mono/blob/main/vital-background-pull/.env.dev) environment file.
All the secrets required for a minimal run are already set.
Depending on the provider you are interested in, you might want to add the corresponding credentials in this file.
For example, if you want to connect to Oura, after creating an application in [Oura's developer dashboard](https://cloud.ouraring.com/oauth/applications),
you can set the following secrets in [.env.dev](https://github.com/adeptlabs/vital-mono/blob/main/vital-background-pull/.env.dev):

```bash
OURA_CLIENT_ID=
OURA_CLIENT_SECRET=
```

<br/>

:::caution
Beware of checking in any sensitive credentials or data in the `.env.dev` file. It is okay when running locally, but it is not recommended to use this file
when deploying Vital. We recommend using an external service to manage your secrets such as [Doppler](https://www.doppler.com).
:::

### Docker compose

Run `docker compose up -d` from the root directory of [vital mono](https://github.com/adeptlabs/vital-mono) to launch Vital's stack.

The following services are created:

<br/>

* `vital_api` - the user facing API.
* `vital_background_pull` - the internal API used for fetching/polling of data from the various providers.
* `pubsub`- a local emulator of GCP's Pub/Sub service.
* `db` - a local instance of PostgreSQL.
* `seeder` - a seeding service that sets up Pub/Sub and the DB.
* `scheduler` - a simple cron job that emulates GCP's CloudScheduler service.

When the services are running, the status looks like this:

```bash
$ docker compose up
NAME                                 COMMAND                  SERVICE                 STATUS              PORTS
vital-mono-db-1                      "docker-entrypoint.s…"   db                      running             0.0.0.0:5432->5432/tcp
vital-mono-pubsub-1                  "./start-pubsub.sh"      pubsub                  running             0.0.0.0:8085->8085/tcp
vital-mono-scheduler-1               "crond -f"               scheduler               running
vital-mono-seeder-1                  "python seed.py"         seeder                  exited (0)
vital-mono-vital_api-1               "uvicorn main:app --…"   vital_api               running             0.0.0.0:80->80/tcp
vital-mono-vital_background_pull-1   "uvicorn main:app --…"   vital_background_pull   running             0.0.0.0:8000->8000/tcp
```

For an additional check that everything works correctly, you can open `http://localhost/docs` (for `vital-api`) and `http://localhost:8000/docs` (for `vital-background-pull`).
These pages contain the Swagger documentation generated by FastAPI, which looks like this:

<br/>

<Image src={"/img/api_generated_docs_page.png"} width={"100%"} />

<br/>

For the db, you can use a tool like [Table Plus](https://tableplus.com) and create a connection with the Postgres credentials from the
[.env.dev](https://github.com/adeptlabs/vital-mono/blob/main/vital-background-pull/.env.dev) file. If the `seeder` service ran correctly, you should see a bunch of tables. The following tables will contain seed data, which will be useful later on when connecting a provider - `source`, `user`, `team`.

:::info
Vital uses the concept of team as unit of authentication. A team can have many users, and each user can connect with many providers. Each team has an api-key that is used
to call the API. The seeder service creates a team for you, which comes with an api-key. To get the api-key, you can go through the logs of the `seeder` service and look for the line `team api key: [YOUR API KEY]`. You can use the api-key to talk with Vital API as shown in the [authentication](/api/authentication) page.
:::

After making sure that everything runs correctly, we can proceed with connecting a provider.

### Creating a connected source

A `ConnectedSource` is a connection between a Vital user and an external provider, e.g. Oura. When a connected source is created, the data fetching starts. We have three types of data fetching:

* Historical - fetches user data prior to the creation of the connection. The default is to fetch 6 months worth of data.
* Daily - fetches user data generated after the connection. Scheduled by a cron job which by default runs every 10 min.
* Webhook - for providers that use webhooks to notify when new data is available, e.g. Fitbit.

To create a connected source, you need two things:

* A Vital user (the `seeder` service already creates one).
* The provider's credentials. For an OAuth2 provider, e.g. Oura, these would be the access token, refresh token and expiry timestamp. You can get those by going through the provider's OAuth2 authorization flow. At a later moment, we will enable running [Vital Link](/vital-link/introduction) from a local setup to automate this, but this is not supported yet.

After you have the credentials, you can use the following script to create a connected source:

```bash
docker compose run vital_api /bin/bash
touch create_connected_source.py # Copy snippet below here.
python create_connected_source.py
```

Use the following python snippet for `create_connected_source.py`:

<CodeBlock title={"Creating a connected source"}>

```python
from api.api_v1.endpoints.vital_api.link import trigger_historical_fetch
from vital_core import crud
from vital_core.db.session import get_engine, get_session
from vital_core.schemas.db_schemas.connected_source import ConnectedSourceCreate
from vital_core.schemas.providers import Providers

PROVIDER_ACCESS_TOKEN: str =
PROVIDER_REFRESH_TOKEN: str =
PROVIDER_EXPIRY_TIMESTAMP: int =

VITAL_USER_ID: str =
VITAL_TEAM_ID: str =
VITAL_SOURCE_ID: int =

conn = ConnectedSourceCreate(
    access_token=f"e:{PROVIDER_ACCESS_TOKEN}",
    refresh_token=f"e:{PROVIDER_REFRESH_TOKEN}",
    expires_at=PROVIDER_EXPIRY_TIMESTAMP,
    user_id=VITAL_USER_ID,
    team_id=VITAL_TEAM_ID,
    source_id=VITAL_SOURCE_ID,
)

async with get_session(get_engine()) as db:
    connected_source = await crud.connected_source.create(db, conn)

trigger_historical_fetch(
    provider=Providers.OURA,  # adjust as required.
    backfill_n_days=180,
    connected_source=connected_source,
)
```

</CodeBlock>

The following constants must be set:

* `PROVIDER_ACCESS_TOKEN`, `PROVIDER_REFRESH_TOKEN`, `PROVIDER_EXPIRY_TIMESTAMP` - these are the OAuth2 provider credentials.
* `VITAL_USER_ID`, `VITAL_TEAM_ID` - this is the Vital user. The seeder service already creates a team and a user for you, so you can
just copy the `id` and `team_id` values from the `user` table in the DB.
* `VITAL_SOURCE_ID` - this is the ID of the data provider, e.g. Oura. The seeder service already populates this in the DB for you, so you can
get the corresponding `id` value from the `source` table.

After the connected source is created, you can check that the data is being fetched in the DB. If you're connecting Oura for example and want sleep data, you can check the `sleepv2` table.

### Notes

* You can adjust the daily polling interval by modifying the [trigger_daily_fetch](https://github.com/adeptlabs/vital-mono/blob/main/docker/cron/trigger_daily_fetch) cron file.
* In the snippet above, provider's credentials are prefixed with "e:". This is because we use [encryption](/welcome/privacy) to store credentials, and our stack is based on it. So adding "e:" to encrypt data and removing "e:" to decrypt is an easy way to simulate encryption.
